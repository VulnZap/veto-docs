---
title: Validation Modes
description: How Veto validates tool calls — cloud, API, custom, and kernel modes.
---

Veto supports four validation modes, configured in `veto.config.yaml`:

```yaml
validation:
  mode: "cloud"  # "cloud", "api", "custom", or "kernel"
```

## Cloud mode

Routes validation through the Veto Cloud API with full policy management, decision logging, and human-in-the-loop approval workflows.

```yaml
validation:
  mode: "cloud"

cloud:
  apiKey: "veto_abc123..."
  baseUrl: "https://api.runveto.com"
  timeout: 30000
  retries: 2

approval:
  pollInterval: 2000   # ms between polls
  timeout: 300000      # max ms to wait (5 min)
```

The cloud can return three decisions:

| Decision | What happens |
|----------|-------------|
| `allow` | Tool call proceeds |
| `deny` | Tool call is blocked |
| `require_approval` | SDK pauses and polls until a human approves or denies |

When `require_approval` is returned, the SDK fires the `onApprovalRequired` hook (TypeScript) or `on_approval_required` callback (Python), then polls `GET /v1/approvals/:id` until resolved. This enables integrations like the Veto dashboard to present approve/deny UI to a human reviewer.

Best for production deployments. Provides:
- Centralized policy management via the dashboard at [runveto.com](https://runveto.com)
- Deterministic and LLM-assisted validation
- Real-time decision logging
- Human-in-the-loop approval workflows
- Team-wide visibility and audit trails

## API mode

Sends validation requests to a self-hosted or external validation API at `POST /tool/call/check`.

```yaml
validation:
  mode: "api"
  api:
    url: "http://localhost:8080"
    endpoint: "/tool/call/check"
```

Best for self-hosted deployments or custom validation backends.

## Custom mode

Calls an LLM provider directly from the SDK. No server needed.

```yaml
validation:
  mode: "custom"

custom:
  provider: "openai"     # openai, anthropic, or gemini
  model: "gpt-4o-mini"
```

Supported providers:

| Provider | Models | Env variable |
|----------|--------|-------------|
| `openai` | `gpt-4o`, `gpt-4o-mini` | `OPENAI_API_KEY` |
| `anthropic` | `claude-sonnet-4-5-20250929` | `ANTHROPIC_API_KEY` |
| `gemini` | `gemini-3-flash-preview` | `GOOGLE_API_KEY` |

Best for development and testing. Rules are evaluated locally using the LLM.

## Kernel mode

Uses a local Ollama model for fully offline validation.

```yaml
validation:
  mode: "kernel"

kernel:
  url: "http://localhost:11434/v1"
  model: "llama3"
```

Requires [Ollama](https://ollama.ai) running locally. Best for air-gapped environments or when you need zero external API calls.

## Operating modes

Separate from validation mode, Veto has two operating modes:

```yaml
mode: "strict"  # or "log"
```

| Mode | Behavior |
|------|----------|
| `strict` | Blocks denied calls — throws `ToolCallDeniedError` |
| `log` | Logs denied calls but allows execution to continue |

Use `log` mode during initial rollout to observe what would be blocked without affecting agent behavior.
